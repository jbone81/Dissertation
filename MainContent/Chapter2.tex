\chapter{\leavevmode\newline Literature Review}\label{chap:chapter_2}

The literature on Digital Engineering tells a story of proven capability confined within disciplinary walls. Model-Based Systems Engineering, digital threads, digital twins, and Product Lifecycle Management have matured through decades of application in defense and aerospace, accumulating institutional endorsement from the Department of War, NASA, and INCOSE alongside rare but compelling empirical evidence of return on investment. Yet this maturation has occurred almost entirely within the systems engineering discipline. Enterprise IT infrastructure management and Information Assurance---domains that confront structurally analogous challenges of documentation accuracy, configuration visibility, compliance traceability, and change coordination---have developed independently, producing their own frameworks, their own tools, and their own patterns of persistent failure. The result is a pronounced research gap: apart from a preliminary reference model by \citeauthor{Bonar_Hastings_2024}~\parencite{Bonar_Hastings_2024} and a conceptual framework for DevSecOps security assurance from the Carnegie Mellon Software Engineering Institute~\parencite{CMU_SEI_DevSecOps_2023}, no peer-reviewed research addresses the application of Digital Engineering methodologies to enterprise IT infrastructure, IT Service Management, or Information Assurance programs broadly.

This chapter examines why that gap persists and why it matters. The review proceeds through an analytical synthesis of research spanning disciplinary evolution, MBSE value evidence, adoption dynamics, cross-disciplinary transfer barriers, digital twin security applications, compliance automation, IT service management failures, and enterprise visibility challenges. Rather than cataloging what exists, the review foregrounds the debates, tensions, and unresolved questions that position this dissertation's investigation within the academic conversation. Four interrelated arguments emerge. First, systems engineering, information assurance, cybersecurity, and IT service management evolved along independent academic and professional trajectories, creating disciplinary silos that explain the absence of cross-disciplinary research. Second, the evidence base for MBSE value, while growing, remains disproportionately reliant upon perceived rather than measured outcomes, creating economic uncertainty that discourages adoption beyond established domains. Third, adoption research demonstrates that perceptions---not objective technical merit---drive adoption decisions, yet no empirical data exist on how IT and Information Assurance professionals perceive Digital Engineering capabilities. Fourth, compliance frameworks and IT service management standards explicitly require capabilities that Digital Engineering provides, yet the academic community has not investigated whether Digital Engineering could fulfill these requirements more effectively than traditional approaches that demonstrably fail.

\section{Parallel Paths: The Independent Evolution of Adjacent Disciplines}

Understanding why no research connects Digital Engineering to enterprise IT and Information Assurance requires understanding how these disciplines evolved along separate trajectories. Each developed its own academic identity, professional communities, curricular standards, and institutional frameworks---despite confronting remarkably similar challenges in documentation, traceability, configuration management, and lifecycle governance. This independent evolution created disciplinary silos so deeply embedded that researchers within each tradition rarely encounter the methodologies of adjacent fields. The result is not a failure of imagination but a structural consequence of how academic disciplines form and maintain boundaries.

Systems engineering emerged as a recognizable discipline in the mid-twentieth century, rooted in large-scale military and industrial programs that demanded coordination across multiple engineering specialties. \citeauthor{Hossain_2020} traced the development across three historical intervals---foundational (1926--1960), exploratory (1961--1989), and contemporary (1990--2017)---observing that the discipline ``is not affirmed by a set of underlying fundamental propositions'' but rather emerged as ``a set of best practices'' consolidated from defense and aerospace experience~\parencite{Hossain_2020}. Hall's foundational \textit{A Methodology for Systems Engineering} (1962) and Goode and Machol's \textit{System Engineering} (1957) established the intellectual architecture, while organizations such as Bell Telephone Laboratories and the RAND Corporation provided the institutional incubators~\parencite{Hossain_2020}. \citeauthor{Honour_2018} reviewed seventy years of the discipline's existence, noting that systems engineering experienced ``rapid growth'' in its early decades followed by ``partial stagnation in the 1990s and 2000s'' as prescriptive process standards displaced first-principles engineering thinking~\parencite{Honour_2018}. This stagnation coincided with precisely the period when enterprise IT complexity was accelerating---a temporal mismatch that helps explain why systems engineering methods were not adopted by IT organizations during the critical window when they might have been most needed.

The disciplinary insularity deepened as systems engineering became increasingly abstract. \citeauthor{Pennotti_2024} traced the evolution from a technical-objective focus through a process and methodology focus toward contemporary calls to return to foundational roots, arguing that systems engineering ``became more abstract and disconnected from the rest of engineering'' when prescriptive processes were developed~\parencite{Pennotti_2024}. As part of INCOSE's Future of Systems Engineering initiative, \citeauthor{Pennotti_2024} characterized systems engineering as inherently transdisciplinary yet insufficiently recognized as such---a characterization that carries direct implications for the present research. If systems engineering's own professional community acknowledges that the discipline has been too insular, the failure to extend its methods to enterprise IT becomes explicable not as a judgment about applicability but as a consequence of disciplinary boundaries that neither community has been motivated to cross.

Crucially, throughout these seven decades of development, systems engineering oriented itself toward physical systems: aircraft, naval vessels, spacecraft, weapons platforms, and industrial control systems. Enterprise information systems---servers, networks, databases, cloud infrastructure, software applications---fell outside the discipline's traditional scope even as these systems grew to exhibit the same characteristics of complexity, interdependency, and emergent behavior that justified systems engineering approaches for physical platforms. The Systems Engineering Body of Knowledge acknowledges this historical trajectory, documenting that systems engineering principles apply to ``engineered systems'' broadly while noting that most published case studies and validated methodologies derive from defense and aerospace contexts~\parencite{SEBoK_2024}.

Information assurance, by contrast, grew from a fundamentally different institutional soil. Where systems engineering emerged from engineering programs and defense laboratories, information assurance developed at the intersection of national security policy and computing education. \citeauthor{Maconachy_2001} formalized the discipline's conceptual foundations in their influential model extending McCumber's 1991 information security cube to encompass five security services---confidentiality, integrity, availability, authentication, and non-repudiation---across three information states and three countermeasure categories~\parencite{Maconachy_2001}. This framework, developed under the auspices of the National Security Agency and Idaho State University's National Information Assurance Training and Education Center, established information assurance as a discipline concerned with the protection and governance of information across its lifecycle rather than with the engineering of the systems that process it. The Committee on National Security Systems codified training standards through NSTISSI documents 4011 through 4016, and the Centers of Academic Excellence in Information Assurance Education program---established in 1998---formalized the academic pipeline~\parencite{Dark_2006}. \citeauthor{Dark_2006} documented how information assurance became a ``pervasive theme'' within IT curricula, embedded within computing education but distinct from the engineering disciplines where systems engineering resided~\parencite{Dark_2006}.

\citeauthor{Cherdantseva_2016} conducted a comprehensive evaluation of information assurance and security models through twenty-six expert interviews, three workshops, and a case study, reviewing the evolution from McCumber's original cube through the Maconachy-Schou-Ragsdale model to their own Reference Model of Information Assurance and Security~\parencite{Cherdantseva_2016}. Their analysis revealed that existing IA models addressed ``trends of diversification and de-perimeterisation'' but focused upon security properties and countermeasures rather than upon the engineering lifecycle processes through which systems are designed, built, and maintained. This focus on protection properties rather than engineering processes represents a fundamental orientation difference from systems engineering---and one that explains why Information Assurance professionals have not encountered Model-Based Systems Engineering in their professional formation.

Cybersecurity's emergence as a standalone academic discipline further fragmented the intellectual landscape. \citeauthor{Parrish_2018} characterized cybersecurity as a ``meta-discipline''---an aggregate label encompassing contributions from computer science, information systems, information technology, software engineering, and electrical engineering~\parencite{Parrish_2018}. Their analysis traced how the 1998 establishment of the CAE/IAE program initiated institutional recognition that evolved from information assurance education into cybersecurity education over two decades. The Joint Task Force on Cybersecurity Education formalized this disciplinary independence through \textit{Cybersecurity Curricula 2017}, the first global curricular guidelines for post-secondary cybersecurity degree programs, organized around eight knowledge areas with contributions from over three hundred advisors across thirty-five countries~\parencite{CSEC2017}. Co-chair Diana Burley acknowledged that ``the field of cybersecurity is in its formative stages''~\parencite{CSEC2017}---a characterization that positions cybersecurity as a discipline still establishing its boundaries rather than one prepared to absorb methodologies from engineering fields with which it shares no curricular lineage.

\citeauthor{Cabaj_2018} examined the evolution of cybersecurity as an academic discipline through analysis of master's programs at leading universities, finding that cybersecurity ``is considered to be evolving at a rapid pace'' compared to other scientific and engineering disciplines~\parencite{Cabaj_2018}. The \textit{Computing Curricula 2020} report---the ACM and IEEE Computer Society's comprehensive overview of computing education---positioned cybersecurity alongside established computing disciplines while documenting how each maintained distinct identities despite shared foundations~\parencite{CC2020}. Chapter 2 of that report traced how computing disciplines evolved since CC2005, revealing a pattern of increasing specialization and decreasing cross-disciplinary integration. Systems engineering does not appear among the computing disciplines at all; it occupies a separate academic lineage rooted in industrial and mechanical engineering departments rather than computing schools. This institutional separation means that cybersecurity and IT graduates rarely encounter systems engineering coursework, and systems engineering graduates rarely encounter information assurance or IT service management content.

IT Service Management developed along yet another independent trajectory---one driven by practitioner communities rather than academic research. \citeauthor{Iden_2013} conducted the foundational systematic literature review of ITSM implementation, examining research published between 2000 and 2012~\parencite{Iden_2013}. Their findings documented that the earliest academic study addressing ITIL adoption appeared in 2005 and the first journal article in 2006---more than fifteen years after ITIL's initial development by the United Kingdom's Central Computer and Telecommunications Agency in the 1980s. This extended gap between practitioner adoption and academic investigation produced a field with extensive operational guidance but limited theoretical grounding. \citeauthor{MacLean_2023} reinforced this assessment in the most recent comprehensive systematic review of ITSM, covering 126 empirical studies from 2012 through 2021 and reconceptualizing ITSM as a Management Control System~\parencite{MacLean_2023}. Their observation that ITSM has been ``undertheorized by academics'' despite widespread practitioner adoption encapsulates the practitioner-academic gap that characterizes the field~\parencite{MacLean_2023}.

\citeauthor{Winniford_2009} documented the consequences of this practitioner-driven evolution, finding significant ``conceptual confusion'' across ITSM models including ITIL, CobiT, BSM, SLM, and ISO/IEC 20000~\parencite{Winniford_2009}. Multiple frameworks addressing overlapping concerns developed without mutual awareness or coordination---a fragmentation pattern that mirrors the broader disciplinary silos this section documents. \citeauthor{Marrone_2014} conducted a cross-national empirical study of 623 respondents from the United Kingdom, United States, German-speaking countries, and Australia, finding that operational ITIL processes achieved substantially higher adoption rates than strategic processes~\parencite{Marrone_2014}. \citeauthor{Serrano_2021} synthesized forty-seven articles in a systematic literature review mapping the ITSM field's evolution since 2002, tracing how ITSM grew from the service management concept emerging in the 1930s through ITIL's development into a distinct professional domain~\parencite{Serrano_2021}. Throughout this evolution, ITSM developed no connection to systems engineering practice. ITIL's process-oriented framework emerged from operational IT management experience rather than from engineering design principles, creating a fundamental methodological incompatibility: ITSM treats IT services as processes to be managed, while systems engineering treats systems as engineered artifacts to be designed, verified, and maintained through lifecycle governance.

The consequence of these parallel evolutionary paths is not merely that Digital Engineering research has not been applied to IT and Information Assurance. Rather, the consequence is that no intellectual infrastructure exists to facilitate such application. Researchers in each discipline publish in different journals, attend different conferences, cite different foundational theorists, and frame problems through different conceptual lenses. A systems engineer describes configuration management as maintaining the consistency of a system's physical and functional attributes with its requirements and design documentation. An IT service manager describes configuration management as maintaining information about configuration items required to deliver IT services. An information assurance professional describes configuration management as establishing and maintaining the integrity of systems through control of changes. These three descriptions address the same operational challenge through three different conceptual vocabularies, each embedded within frameworks that do not reference one another. The research gap this dissertation investigates is, at its root, a gap between disciplines that never developed the shared vocabulary necessary for methodological exchange.

\section{The Evidence Paradox: Demonstrated Value Without Sufficient Proof}

The case for Model-Based Systems Engineering rests upon a paradox that shapes the entire adoption landscape: practitioners and organizations widely perceive MBSE as valuable, yet rigorous empirical measurement of that value remains exceptionally rare. Understanding this paradox is essential because it explains both why MBSE has succeeded within systems engineering and why it has not expanded beyond it. Organizations already embedded in the systems engineering discipline can rely upon institutional experience and professional networks to validate MBSE investment. Organizations outside the discipline---including enterprise IT and Information Assurance---lack comparable experiential evidence and must rely upon published research that, as the literature reveals, provides insufficient quantitative justification.

The most comprehensive assessment of MBSE evidence comes from \citeauthor{Henderson_Salado_2021}, whose systematic literature review categorized reported benefits into four evidence types: measured, observed, perceived, and referenced~\parencite{Henderson_Salado_2021}. A finding of considerable consequence emerges: approximately two-thirds of claimed MBSE benefits lack empirical measurement and instead rely upon perceived or referenced evidence, carrying profound implications for adoption decisions. Organizations evaluating MBSE investment discover that the research literature offers abundant testimony to MBSE's promise but limited quantified outcomes upon which to build business cases. \citeauthor{Madni_Sievers_2018} reached a similar conclusion in their review of MBSE motivation and research opportunities, arguing that the value proposition requires demonstration through real-world applications and that further advancements remain necessary before broader adoption can occur~\parencite{Madni_Sievers_2018}. The more recent systematic literature review by \citeauthor{Wooley_Womack_2025} analyzed adoption, benefits, and challenges across the Digital Engineering research corpus and explicitly noted the absence of research addressing enterprise IT infrastructure or Information Assurance applications~\parencite{Wooley_Womack_2025}. This finding validates that the research gap identified in this dissertation reflects the actual state of academic literature rather than incomplete literature search.

Among the rare exceptions to the measurement deficit, the work of \citeauthor{Rogers_Mitchell_2021} stands as the most frequently cited quantified evidence of MBSE return on investment~\parencite{Rogers_Mitchell_2021}. Their case study examined the Submarine Warfare Federated Tactical Systems program---a rapidly evolving combat system of systems comprising over ten million source lines of code deployed across 104 submarines---following a three million dollar MBSE investment over two and a half years. An apples-to-apples comparison between legacy document-centric processes and the MBSE approach revealed that systems engineering hours per requirement decreased from 12.1 to 9.9, representing an eighteen percent improvement in efficiency that exceeded the thirteen percent improvement projected by an earlier pilot study. The MBSE approach handled forty-two percent more interface requirements changes while consuming only sixteen percent more hours, reduced total interface defects by nine percent, and shifted eighteen percent of defects to earlier discovery phases where correction costs between 1.6 and 4 times less than defects discovered during platform integration testing. Supplementary data demonstrated thirty percent more baselines produced monthly and sixty percent more integrated subsystems and combat system variants managed within constant resources.

These results are significant not merely for their magnitude but for their scarcity. \citeauthor{Henderson_Salado_2021} identified the Rogers and Mitchell study as one of only two papers in the literature reporting measured MBSE return on investment evidence~\parencite{Henderson_Salado_2021}. Subsequent efforts to address this measurement deficit have advanced the methodological conversation without resolving it. \citeauthor{Henderson_2023_Metrics} developed a measurement framework for selecting and developing metrics to assess MBSE and Digital Engineering value, including causal maps of expected benefits~\parencite{Henderson_2023_Metrics}. \citeauthor{Campo_2023} evaluated MBSE's perceived value by analyzing attributes, benefits, and drawbacks reported in the literature, finding a persistent gap between what practitioners believe MBSE delivers and what published evidence can substantiate~\parencite{Campo_2023}. Both studies underscore a recurring theme: the systems engineering community recognizes the measurement deficit and has begun developing frameworks to address it, yet empirical data from operational programs remain rare. For enterprise IT organizations operating on annual budgets with continuous delivery expectations, this evidentiary deficit creates a rational basis for hesitation: the demonstrated benefits derive from a naval combat system program operating under a level-of-effort contract structure fundamentally different from enterprise IT budget models. Whether comparable returns would materialize in enterprise IT contexts remains entirely unexamined.

Earlier systematic reviews reinforce this pattern. \citeauthor{Wolny_2020} reviewed thirteen years of SysML research, mapping the landscape of model-based methods and their empirical evidence~\parencite{Wolny_2020}. \citeauthor{Chami_Bruel_2018} surveyed MBSE tools and applications, finding consistent reports of improved requirements traceability and stakeholder communication alongside persistent concerns about tool complexity and organizational adoption challenges~\parencite{Chami_Bruel_2018}. Research by \citeauthor{gregory2019model} examined model-based engineering practices within defense programs, documenting improved requirements traceability and more effective design reviews but also identifying organizational and technical barriers that limit realization of theoretical benefits~\parencite{gregory2019model}. Collectively, these reviews establish that MBSE has demonstrated value across multiple domains while simultaneously documenting two critical limitations: the evidence remains predominantly qualitative, and the domains of application remain overwhelmingly confined to aerospace and defense.

The tension between demonstrated capability and insufficient proof creates what might be termed an adoption credibility gap. Within the systems engineering discipline, professional experience and institutional knowledge compensate for the measurement deficit. Systems engineers who have used MBSE tools can observe improvements in their own work, creating the experiential validation that published evidence lacks. Outside the discipline, this compensatory mechanism does not operate. IT and Information Assurance professionals have no experiential basis for evaluating MBSE claims. The literature provides them with compelling arguments but insufficient evidence---a combination that technology adoption research suggests is inadequate for driving adoption decisions.

\section{Adoption as a Perception Problem}

If the evidence paradox explains why MBSE has not expanded through rational economic calculation, the adoption literature reveals a complementary explanation rooted in perception dynamics. A growing body of empirical research demonstrates that MBSE adoption decisions are driven more by how professionals perceive the technology than by its objective characteristics. This finding carries direct implications for the present research: if perceptions govern adoption even among systems engineering professionals who work with models daily, understanding perceptions among IT and Information Assurance professionals---who have never systematically encountered these methodologies---becomes a prerequisite for any meaningful discussion of cross-disciplinary transfer.

The theoretical foundation for this argument derives from \citeauthor{Call_Herber_2022}, who mapped Everett Rogers' Diffusion of Innovations theory to MBSE adoption dynamics~\parencite{Call_Herber_2022}. Rogers' framework identifies five perceived attributes of innovations---relative advantage, compatibility, complexity, trialability, and observability---that collectively account for forty-nine to eighty-seven percent of variance in adoption rates across innovation research. The critical theoretical insight, and the one most consequential for the present research, is that \textit{perceptions} of these attributes, not the attributes themselves, drive adoption behavior. \citeauthor{Call_Herber_2022} invoke W.~I.~Thomas's dictum that ``if [people] perceive situations as real, they are real in their consequences,'' arguing that shaping how MBSE attributes are perceived can accelerate adoption rates more effectively than improving the attributes themselves~\parencite{Call_Herber_2022}.

The empirical follow-up by \citeauthor{Call_2024} tested this theoretical mapping through a survey of approximately 270 systems engineering professionals distributed through INCOSE and professional networks~\parencite{Call_2024}. The study examined perceptions across six subpopulation comparisons---involved versus not involved in MBSE efforts, model users versus non-users, and respondents subject to Digital Engineering mandates versus those who are not. Respondents broadly recognized MBSE's relative advantage in improving data quality and traceability. However, perceived compatibility with existing practices and perceived complexity emerged as significant barriers that suppressed adoption even when practitioners acknowledged objective value.

The most striking finding involves trialability. Respondents not involved in MBSE efforts reported dramatically lower access to trial opportunities and tools, with a chi-squared test result of \(p=0.00\) for the involved/non-involved comparison~\parencite{Call_2024}. This creates what \citeauthor{Call_2024} characterize as a barrier-reinforcing cycle: professionals who have not experienced MBSE cannot access the trial opportunities that would facilitate informed adoption decisions, while those who have experienced MBSE report substantially more favorable perceptions. The study further characterizes MBSE as a ``preventative innovation'' whose advantages derive from preventing problems---inconsistencies, documentation errors, rework---rather than producing visible new benefits. This characteristic depresses both perceived relative advantage and observability, compounding adoption barriers even when objective value exists.

This perception-adoption dynamic has profound implications for cross-disciplinary transfer. If systems engineering professionals---practitioners who work within the discipline that developed MBSE---exhibit perception gaps that impede adoption, the perception barriers among IT and Information Assurance professionals are likely to be substantially greater. These professionals operate outside the systems engineering discipline entirely. They have no professional exposure to MBSE concepts, no institutional networks sharing MBSE experiences, and no trial opportunities through which favorable perceptions might develop. The present research addresses this gap by measuring perceptions in a population where no empirical data currently exist.

Complementary evidence from \citeauthor{Henderson_McDermott_Salado_2024} deepens understanding of adoption dynamics through a mixed-methods study combining systematic literature review with eighteen semi-structured practitioner interviews from organizations attempting MBSE adoption~\parencite{Henderson_McDermott_Salado_2024}. The literature review extracted over six hundred individual lessons learned from forty-six published papers, coded into categories spanning communication, model definition, organizational strategy, and technical implementation. The interview findings illuminate the human dimensions of adoption that quantitative studies cannot fully capture. Perhaps most directly relevant to the question of professional awareness, approximately twenty-two percent of interview participants---all systems engineering professionals---could not convey a clear definition of MBSE\@. One participant captured the prevailing confusion: ``Most people think of MBSE as being synonymous with a specific tool'' and ``don't understand how MBSE fits into DE or what it really does other than it is modeling instead of documents''~\parencite{Henderson_McDermott_Salado_2024}. Another stated plainly that ``if they aren't familiar with MBSE, they're not going to use it.''

The organizational lessons proved equally revealing. For both organizations in the study whose adoption efforts failed, the driving barrier was lack of management support. Middle management resistance proved particularly insidious because executives endorsed MBSE while middle managers could disregard the endorsement without operational consequences. Successful adopters commonly established core MBSE teams---communities of practice or centers of excellence---and implemented role-based training at four levels: model reviewers for leaders and decision-makers, developers and modelers, architects for senior engineers, and administrators for IT and software support. A reinforcing dynamic emerged: greater stakeholder exposure to models produced more perceived benefits, which generated more organizational buy-in, which enabled further exposure. This virtuous cycle operates within organizations that have initiated adoption but cannot initiate itself in domains where MBSE has never been introduced. \citeauthor{McDermott_2024} synthesized five years of research on Digital Engineering and MBSE adoption into an enterprise adoption framework, presenting a model of factors spanning organizational design, enablers and barriers, and change management~\parencite{McDermott_2024}. Their research confirmed that adoption requires coordinated action across multiple organizational dimensions simultaneously---a finding that compounds the challenge for enterprise IT organizations unfamiliar with the discipline.

\citeauthor{Henderson_Salado_2024_Org} extended these findings by examining how organizational structure variables correlate with MBSE adoption outcomes through a survey of fifty-one practitioners~\parencite{Henderson_Salado_2024_Org}. The results reveal a pattern with direct implications for enterprise IT contexts. Flexibility and interconnectedness showed the strongest and most consistent positive correlations with both adoption process and implementation variables. Formalization---documented procedures and processes---correlated positively, a somewhat counterintuitive finding suggesting that governance frameworks support rather than hinder adoption when combined with flexibility. Centralization correlated negatively with adoption and implementation, as did large organizational size and high vertical differentiation. These structural findings suggest that enterprise IT organizations characterized by rigid hierarchies, centralized governance, and siloed operations may face structural impediments to Digital Engineering adoption that compound the perception barriers documented by \citeauthor{Call_2024}.

Research beyond the systems engineering discipline corroborates and extends these dynamics. \citeauthor{Vogelsang_2017} conducted a qualitative study of twenty interviews across ten companies in the embedded systems industry---outside the defense and aerospace sector where MBSE originated~\parencite{Vogelsang_2017}. Their findings identified immature tooling, return on investment uncertainty, and migration fears as key barriers, confirming that the adoption challenges documented within systems engineering intensify when the technology crosses disciplinary boundaries. \citeauthor{Campagna_2024} examined strategic adoption of digital innovations more broadly, finding that digital transformation requires coordinated enterprise-level application rather than bottom-up adoption of individual technologies~\parencite{Campagna_2024}. The research identified twelve strategic adoption influencers and noted that adoption research focuses upon individual technologies rather than integrated digital transformation---a finding that explains why platform-level Digital Engineering adoption within defense programs has not expanded to enterprise IT functions operating separately from program organizations.

The technology adoption literature addressing cybersecurity and IT contexts provides a parallel body of evidence that has not been connected to the Digital Engineering adoption discourse. \citeauthor{Hasani_2023} integrated Diffusion of Innovation, the Technology Acceptance Model, and the Technology-Organization-Environment framework with a balanced scorecard approach, surveying 147 IT experts in United Kingdom small and medium enterprises to identify factors affecting cybersecurity technology adoption~\parencite{Hasani_2023}. Their study represents one of the few empirical investigations combining multiple adoption models in a cybersecurity context, identifying eight key factors including organizational IT readiness, perceived ease of use, and management support---factors that parallel the MBSE adoption barriers documented by \citeauthor{Henderson_McDermott_Salado_2024}. \citeauthor{Alghamdi_2023} developed a cybersecurity-specific extension of the Unified Theory of Acceptance and Use of Technology, surveying 108 IT professionals and 554 public respondents to examine cybersecurity adoption in smart city contexts~\parencite{Alghamdi_2023}. \citeauthor{Anthony_2024} applied Rogers' Diffusion of Innovations framework---the same theoretical foundation used by \citeauthor{Call_2024} for MBSE---to examine motivations and barriers for advanced cybersecurity tool adoption in high-threat industries~\parencite{Anthony_2024}. That cybersecurity researchers independently selected the same adoption theory applied by MBSE adoption researchers underscores the theoretical compatibility between these fields despite their practical isolation.

At the organizational level, \citeauthor{Ali_2022} conducted a large-scale empirical study using data from 1,988 company executives to examine IT innovation adoption factors, finding that organizational IT innovation readiness---encompassing both technology readiness and internal expertise---serves as a key mediator of adoption outcomes~\parencite{Ali_2022}. \citeauthor{Shahadat_2023} combined Diffusion of Innovation and Technology-Organization-Environment frameworks, surveying 535 managers and finding that relative advantage, complexity, observability, top management support, and competitive pressure serve as significant determinants of digital technology adoption~\parencite{Shahadat_2023}. These organizational-level findings parallel the structural variables examined by \citeauthor{Henderson_Salado_2024_Org} in the MBSE context, suggesting that common adoption dynamics operate across technology domains even when the specific technologies differ. However, no study has examined these dynamics for Digital Engineering adoption within IT or Information Assurance populations---leaving the critical question of whether Digital Engineering would follow similar adoption patterns in these contexts entirely unanswered.

The adoption literature thus establishes a critical precondition for the present research. Technology adoption is governed by perceptions. Perceptions among systems engineering professionals---the population most favorably positioned to appreciate MBSE---remain mixed and marked by significant awareness deficits. Cybersecurity and IT adoption research reveals parallel dynamics operating through the same theoretical frameworks. Yet no study bridges these parallel tracks by examining Digital Engineering perceptions among IT and Information Assurance professionals. Until such data are collected, any discussion of Digital Engineering adoption beyond defense and aerospace rests upon assumption rather than evidence. This dissertation addresses that evidentiary gap.

\section{Crossing Disciplinary Boundaries: Digital Engineering Beyond Its Origins}

The concentration of Digital Engineering within aerospace and defense raises an unresolved question that the literature has acknowledged but not adequately investigated: can these methodologies transfer effectively to domains with different professional cultures, tool ecosystems, and economic structures? The preliminary evidence is suggestive but fragmented, consisting of isolated applications to security domains, a conceptual framework from an authoritative institution, emerging applications in healthcare and manufacturing, and a single systematic mapping study of model-based security engineering. No sustained research program has examined cross-disciplinary transfer to enterprise IT or Information Assurance.

\citeauthor{Bone_Blackburn_2019} described the Systems Engineering Research Center's research effort underlying the DoD Digital Engineering initiative, identifying three key enablers for transformation: IT infrastructure, workforce development, and policy~\parencite{Bone_Blackburn_2019}. Though defense-originated, their analysis addressed cross-cutting adoption dynamics and workforce transformation challenges applicable to any domain adopting Digital Engineering. The transformation they described requires coordinated investment across technology, people, and governance---precisely the integrated approach that enterprise IT organizations, structured around operational silos and annual budget cycles, struggle to sustain.

The most substantive bridge between Digital Engineering and Information Assurance comes from the Carnegie Mellon Software Engineering Institute. \citeauthor{CMU_SEI_DevSecOps_2023} argued that DevSecOps pipelines constitute complex socio-technical systems---comprising independently developed and maintained, physically and logically distributed, interoperable components---that require systems engineering treatment~\parencite{CMU_SEI_DevSecOps_2023}. The tight integration of business mission, capability delivery, and products ``increases the attack surface of the product under development,'' and as organizations adopt DevSecOps tools and techniques with increased coupling between products and the tools used to build them, ``the attack surface continues to grow, incorporating segments of the development environment itself.'' The research developed a DevSecOps Platform Independent Model using the Unified Architecture Framework and SysML to model pipeline security properties, demonstrating how to construct cybersecurity assurance cases from model-based representations.

The SEI framework proposed a conceptual shift with direct relevance to this dissertation: from process-based to property-based security assurance. Traditional cybersecurity assurance relies upon process-based standards such as the NIST Risk Management Framework and SP~800-53 security controls. As systems become more complicated and interconnected, \citeauthor{CMU_SEI_DevSecOps_2023} argued, ``process-based standards fail to assure system owners that the system functions only as intended under all operational circumstances''~\parencite{CMU_SEI_DevSecOps_2023}. When MBSE-based assurance is implemented effectively, ``the overall risks associated with the DevSecOps pipeline and associated products will be reduced, and the compliance and legal requirements will naturally be addressed within the engineering lifecycle.'' This finding directly supports the theoretical premise of this dissertation: that Digital Engineering capabilities can integrate security engineering into development and operational processes rather than treating compliance as a separate activity conducted after the fact.

However, the SEI framework represents a conceptual and architectural argument rather than empirical validation. The research demonstrates technical feasibility through detailed modeling of configuration management capabilities but does not provide quantitative effectiveness data. The framework was designed for heavily regulated and cybersecurity-constrained environments including defense, banking, and healthcare---domains where Information Assurance professionals operate and where compliance verification demands consume substantial organizational resources. The absence of empirical validation leaves the critical question unanswered: does MBSE-based security assurance deliver measurable improvements over traditional compliance approaches in practice?

Beyond the SEI framework, emerging research has begun applying MBSE to non-defense domains, though these applications remain isolated and preliminary. \citeauthor{Gordon_Reilly_2023} proposed an MBSE methodology for capturing cybersecurity requirements in space systems using SysML within Cameo Systems Modeler, expanding upon NIST cyber resiliency frameworks to demonstrate how model-based approaches can structure security analysis within an engineering lifecycle~\parencite{Gordon_Reilly_2023}. \citeauthor{Berg_2023} conducted a scoping review of MBSE methods applied to rural healthcare system disaster planning, demonstrating that model-based approaches can organize complex interdependencies beyond traditional engineering contexts~\parencite{Berg_2023}. \citeauthor{Xames_2024} performed a rapid review covering twelve years of MBSE utilization in healthcare systems, identifying applications ranging from patient flow modeling to wellness digital twins~\parencite{Xames_2024}. \citeauthor{Badenko_2024} developed a practical MBSE methodology for digital transformation of existing industrial enterprises---a non-defense application demonstrating feasibility outside the discipline's traditional domains~\parencite{Badenko_2024}. \citeauthor{Bolshakov_2023} reviewed cross-industry principles for digital representations of complex technical systems using the MBSE approach, explicitly addressing applications beyond defense and aerospace~\parencite{Bolshakov_2023}.

Other researchers have probed adjacent territory without directly addressing enterprise IT\@. \citeauthor{Huff_Medal_2019} developed an MBSE methodology for critical infrastructure vulnerability assessment and decision analysis, using DoDAF-based modeling to link regulatory requirements, system architecture, and attack vectors~\parencite{Huff_Medal_2019}. Their work demonstrates MBSE application to infrastructure protection and security assessment beyond traditional platform engineering but does not extend to enterprise IT infrastructure management. \citeauthor{Mazeika_Butleris_2020} presented a UML-based MBSE security profile conforming to ISO/IEC 27001 and found through a feasibility survey of ten engineering companies that security aspects are inadequately addressed by standard SysML and popular MBSE methods~\parencite{Mazeika_Butleris_2020}. This finding identifies a tool gap that would impede adoption even if organizational and perception barriers were overcome: the modeling languages themselves require extension to accommodate security constructs that enterprise IT and Information Assurance demand. \citeauthor{Apvrille_Roudier_2015} proposed SysML-SecA, combining SysML with security analysis techniques for integrated threat modeling~\parencite{Apvrille_Roudier_2015}. These preliminary investigations establish that researchers have recognized the potential of MBSE for security applications while simultaneously documenting the technical, methodological, and empirical gaps that separate potential from realization.

\citeauthor{Nguyen_Ali_Yue_2017} conducted a systematic mapping of forty-eight primary studies on model-based security engineering for cyber-physical systems~\parencite{Nguyen_Ali_Yue_2017}. The study found that most research uses domain-specific languages or UML, focuses upon early lifecycle stages, and addresses threats, attacks, and vulnerabilities generically. This mapping reveals a field in its formative stages---one where foundational concepts are being established but where mature, validated methodologies for operational security engineering have not yet emerged. The gap between model-based security engineering research and operational Information Assurance practice remains substantial.

The academic literature on MBSE applications thus presents a landscape of expanding interest constrained by limited evidence. Researchers have begun exploring applications to security domains, infrastructure protection, healthcare systems, and compliance frameworks. Authoritative institutions have produced conceptual frameworks demonstrating technical feasibility. Yet the enterprise IT context---where organizations manage heterogeneous infrastructure, maintain compliance across multiple regulatory frameworks, and coordinate service delivery across organizational silos---remains conspicuously absent from the research. The frameworks exist; the methodologies have matured; the tools have proliferated. What the cybersecurity skills gap analysis by \citeauthor{Ramezan_2023}, examining 935 cybersecurity positions across nine sub-fields, underscores is that cybersecurity professionals operate within specialized roles that share no curricular or experiential overlap with systems engineering practice~\parencite{Ramezan_2023}. The research community has not bridged this gap, and the professional communities have not demanded it.

\section{Digital Twins as Emerging Security Tools}

Digital twin technology has generated substantial research interest in cybersecurity applications, creating a parallel track to MBSE-based security engineering that the literature has not yet integrated into a coherent Digital Engineering narrative. The growing body of research on digital twins for security purposes represents both an opportunity and an analytical challenge: it demonstrates that Digital Engineering concepts are penetrating security domains, but it does so through a technology-specific lens that misses the integrated approach---combining MBSE, digital threads, digital twins, and PLM---that characterizes Digital Engineering as a discipline.

\citeauthor{Grieves_2023} traces the evolution of digital twin concepts from Product Lifecycle Management origins through contemporary applications, positioning digital twins as the integration of physical and virtual systems that enables analysis, optimization, and prediction~\parencite{Grieves_2023}. The foundational distinction between digital twins and traditional simulation lies in synchronization: digital twins maintain continuous data exchange with their physical or logical counterparts, enabling operational decision-making based upon current rather than documented system states. \citeauthor{madni2018leveraging} provided an influential framework for leveraging digital twins in systems engineering contexts, establishing the conceptual architecture that subsequent security applications adapted~\parencite{madni2018leveraging}.

Maturation of digital twin security research is evidenced by the proliferation of systematic reviews and comprehensive surveys in recent years. \citeauthor{Alcaraz_Lopez_2022} published the seminal survey in \textit{IEEE Communications Surveys and Tutorials}---a venue with an impact factor exceeding thirty---classifying security threats across five digital twin components and establishing the analytical framework that subsequent research has adopted~\parencite{Alcaraz_Lopez_2022}. With over three hundred citations, this survey represents the most authoritative assessment of the digital twin security landscape. The systematic literature review by \citeauthor{ElHajj_2024} analyzed sixty-seven papers published between 2018 and 2023 examining how digital twins enhance security in Industry 4.0 applications~\parencite{ElHajj_2024}. Covering intrusion detection, vulnerability assessment, cyber range simulation, and threat intelligence applications, the review identified enabling technologies---machine learning, blockchain, and 5G---used in conjunction with digital twins for security purposes. \citeauthor{Alhumam_2025} extended this analysis in a comprehensive review categorizing digital twin cybersecurity studies by technique type and digital twin level---component, process, asset, system, and network-of-systems---assessing risk levels from medium to very high depending upon twin type and industry sector~\parencite{Alhumam_2025}. \citeauthor{Jeremiah_2024} contributed a three-dimensional security framework mapping security risks across digital twin architectural layers and application domains, providing a structured taxonomy for understanding where security challenges concentrate~\parencite{Jeremiah_2024}. \citeauthor{Qureshi_2025} surveyed digital twin modeling techniques for cybersecurity, classifying security operation modes into analytics, simulation, and replication while reviewing both open-source tools and commercial platforms~\parencite{Qureshi_2025}. These systematic reviews confirm that digital twin security applications have achieved sufficient research volume to warrant meta-analysis, indicating a maturing research area.

Within this expanding literature, several streams bear directly upon Information Assurance and enterprise IT applications. \citeauthor{Eckhart_Ekelhart_2019} reviewed digital twins for cyber-physical systems security, examining how virtual replicas can support security testing and analysis without affecting operational systems~\parencite{Eckhart_Ekelhart_2019}. \citeauthor{Vielberth_2021} proposed a digital twin-based cyber range for Security Operations Center analyst training, demonstrating practical application of digital twin concepts to security workforce development~\parencite{Vielberth_2021}. \citeauthor{Dietz_Pernul_2020} examined digital twins for enterprise security, exploring how organizations might employ virtual representations to understand and manage security postures~\parencite{Dietz_Pernul_2020}. \citeauthor{Karaarslan_Babiker_2021} examined digital twin security threats and countermeasures, addressing the bidirectional security challenge: digital twins can enhance security while simultaneously introducing new attack surfaces~\parencite{Karaarslan_Babiker_2021}. More recently, \citeauthor{Erceylan_2025} evaluated digital twin capabilities for enhancing threat modeling across the cyber-physical system lifecycle, demonstrating how continuous synchronization between virtual and physical representations enables dynamic risk assessment~\parencite{Erceylan_2025}. \citeauthor{Kampourakis_2025} conducted a systematic review analyzing twenty-seven articles on digital twins for incident detection and response in critical infrastructure, identifying persistent gaps in scalability, interoperability with legacy systems, and real-world validation~\parencite{Kampourakis_2025}. These gaps---particularly interoperability with legacy systems and validation in operational environments---represent precisely the challenges that enterprise IT organizations would confront in digital twin adoption.

Standards development further indicates maturing technology readiness. \citeauthor{Shao_2021} examined ISO 23247 and IEC 62832 standards for digital twin frameworks~\parencite{Shao_2021}. \citeauthor{Shao_ISO_23247_2023} provided additional analysis of ISO 23247's four-part structure~\parencite{Shao_ISO_23247_2023}. The Internet Engineering Task Force has published a draft reference architecture for network infrastructure digital twins~\parencite{IETF_NDT_2024}. These standardization efforts establish interoperability requirements that reduce vendor lock-in concerns and enable integration across implementations.

NIST's engagement with digital twin technology illuminates the current state of institutional thinking. NIST Internal Report 8356 addresses cybersecurity challenges and trust considerations for digital twin implementations~\parencite{NIST_IR_8356_2025}. Significantly, this publication addresses security considerations \textit{for} systems employing digital twins rather than digital twin applications \textit{to} Information Assurance. The distinction is revealing: NIST examines how to secure digital twin implementations rather than how digital twins might enhance security posture visibility or compliance verification. This framing reflects the current state of institutional research: digital twins are treated as systems to be secured rather than as tools for improving security operations.

\subsection{Security Risks of Improperly Secured Digital Twins}

While the preceding discussion examines digital twins as security-enhancing tools, the literature reveals an equally important and less frequently addressed concern: improperly secured digital twins themselves become attack vectors that adversaries can exploit. Because a digital twin faithfully replicates the architecture, configuration, and behavioral characteristics of its physical or logical counterpart, unauthorized access to a digital twin grants an attacker a comprehensive reconnaissance platform---one that reveals system vulnerabilities, operational patterns, and interdependencies without triggering alerts on the production environment. \citeauthor{Suhail_Iqbal_Jurdak_2024} framed this danger through the concept of the ``evil digital twin,'' warning that adversaries who compromise or construct malicious virtual replicas can leverage them to rehearse attacks, identify exploitable weaknesses, and craft intrusion strategies with a precision that traditional reconnaissance cannot match~\parencite{Suhail_Iqbal_Jurdak_2024}. Published in \textit{Communications of the ACM}, their analysis identified data poisoning, model manipulation, and feedback loop corruption as three vectors through which compromised twins propagate harm back to physical systems.

Empirical threat analysis corroborates these concerns. \citeauthor{Alcaraz_Lopez_2022}, in the most widely cited survey of digital twin security threats, classified attacks across five architectural components---physical entity, communication channel, data storage, virtual model, and application layer---demonstrating that each component introduces distinct exploitation opportunities~\parencite{Alcaraz_Lopez_2022}. Their taxonomy established that synchronization mechanisms, while essential for twin fidelity, simultaneously create bidirectional pathways through which adversaries can inject false data into the physical system or exfiltrate sensitive operational intelligence from the virtual replica. \citeauthor{Jeremiah_2024} extended this analysis through a three-dimensional security framework mapping risks across digital twin architectural layers and application domains, finding that risk severity escalates from medium to very high as twin fidelity and system-of-systems integration increase~\parencite{Jeremiah_2024}. Higher-fidelity twins, precisely because they model systems more accurately, provide attackers with more actionable intelligence when compromised.

\citeauthor{Holmes_2021} posed the question directly: are digital twins a cybersecurity solution or a cybersecurity challenge? Their analysis concluded that the answer depends entirely upon implementation rigor~\parencite{Holmes_2021}. Organizations that deploy digital twins without embedding security controls throughout the twin lifecycle---from design through data ingestion to model synchronization---create shadow representations of critical infrastructure that bypass the security controls protecting the physical systems themselves. \citeauthor{Karaarslan_Babiker_2021} cataloged specific countermeasures including authentication protocols for twin-physical communication channels, encryption of twin state data, and integrity verification mechanisms for synchronization updates~\parencite{Karaarslan_Babiker_2021}. Yet their review found that many implementations prioritize functional fidelity over security hardening, leaving twins exposed to manipulation.

\citeauthor{Suhail_ENIGMA_2023} proposed ENIGMA, an explainable digital twin security solution for cyber-physical systems, specifically addressing the challenge of detecting when a digital twin has been subverted~\parencite{Suhail_ENIGMA_2023}. Their framework employs explainable artificial intelligence to identify anomalous divergences between twin predictions and physical system behavior---divergences that may indicate adversarial manipulation of the twin model. \citeauthor{Jiang_2024_CPPS} demonstrated complementary capabilities in a cyber-physical production systems context, developing a digital twin security model that enhances asset visibility and supports vulnerability prioritization through virtual testing, while simultaneously documenting forty-one vulnerability instances across fourteen critical components that twin-based analysis revealed~\parencite{Jiang_2024_CPPS}.

For Information Assurance practice, these exploitation risks carry particular significance. Organizations contemplating digital twins for compliance verification or security posture management must recognize that the twin itself becomes a high-value target requiring its own security controls, authorization boundaries, and continuous monitoring---precisely the governance mechanisms that the RMF prescribes for any information system processing sensitive data. NIST Internal Report 8356 acknowledges this recursive security challenge, establishing trust considerations for digital twin deployments that include data integrity verification, access control requirements, and lifecycle security management~\parencite{NIST_IR_8356_2025}. An unresolved tension persists in the literature: researchers advocate digital twins as tools for improving security visibility while simultaneously documenting that inadequately secured twins expand the very attack surface they are intended to reduce. Resolving this tension requires integrating digital twin security within the broader Digital Engineering framework---connecting twin security to digital thread traceability, MBSE-based security architecture, and PLM lifecycle governance---rather than treating twin security as an isolated concern. No published research examines this integrated approach for enterprise IT contexts.

The academic research on open source digital twin frameworks adds another dimension to the adoption question. \citeauthor{Gil_2024} conducted a systematic survey of open source digital twin frameworks, analyzing fourteen frameworks against criteria derived from ISO 23247 standards and finding significant variation in maturity, documentation quality, and community support~\parencite{Gil_2024}. \citeauthor{Autiosalo_Siegel_Tammi_2021} introduced Twinbase, an open source server for the Digital Twin Web concept~\parencite{Autiosalo_Siegel_Tammi_2021}. These open source options reduce economic barriers to adoption but do not resolve the more fundamental challenge: digital twin applications for enterprise IT contexts lack the academic research and validated methodologies that would guide adoption decisions.

The digital twin security literature thus reveals a field developing in parallel with but largely disconnected from the broader Digital Engineering discourse. Researchers explore digital twins as security tools without embedding their work within the Digital Engineering framework that integrates MBSE, digital threads, and PLM into a coherent discipline. This disconnection means that individual digital twin security capabilities are investigated in isolation rather than as components of the integrated approach that defense and aerospace organizations employ. Whether integrating digital twin security capabilities within a comprehensive Digital Engineering framework would produce greater value than isolated implementations remains an open question---one that the absence of enterprise IT research leaves entirely unaddressed.

\section{The Compliance Imperative and Its Unfulfilled Requirements}\label{sec:compliance_imperative}

Compliance frameworks create requirements that Digital Engineering could address, yet no research examines Digital Engineering approaches to satisfying these requirements. This disconnect between what frameworks demand and what current practices deliver represents one of the most compelling arguments for investigating Digital Engineering application to Information Assurance.

The NIST Risk Management Framework, documented in Special Publication 800-37 Revision 2, provides the authoritative approach to managing security and privacy risk for federal information systems through seven iterative steps: prepare, categorize, select, implement, assess, authorize, and monitor~\parencite{NIST_SP_800_37_R2_2018}. The RMF explicitly requires enterprise architecture integration during the prepare step. Yet compliance with this requirement assumes capabilities that organizations demonstrably lack: the ability to maintain accurate, current documentation of enterprise architecture that reflects operational reality. NIST Special Publication 800-53 Revision 5 compounds these demands through specific controls requiring enterprise architecture capabilities: PL-2 requires security plans consistent with enterprise architecture; PL-8 requires security architecture development; PM-7 establishes enterprise architecture requirements; CM-2 requires documented baselines; CM-8 requires accurate system component inventory; SA-17 requires design specifications consistent with enterprise architecture~\parencite{Force_2020}. Each control establishes compliance obligations that Digital Engineering could address. Yet no research examines Digital Engineering approaches to satisfying these specific controls.

The Committee on National Security Systems Instruction 1253 extends these requirements to national security systems, where documentation and visibility challenges compound under additional constraints~\parencite{CNSSI_1253_2022}. Organizations operating outside federal requirements may employ ISO/IEC 27001:2022 for information security management~\parencite{ISO27001-2023}. \citeauthor{Mazeika_Butleris_2020} found that standard MBSE methods inadequately address ISO 27001 security requirements, identifying a specific gap between what compliance frameworks demand and what current modeling approaches provide~\parencite{Mazeika_Butleris_2020}. These alternative frameworks share a common characteristic with NIST guidance: they assume documentation accuracy and visibility capabilities that organizations struggle to maintain.

NIST's systems security engineering publications establish principles that align with Digital Engineering's integrated approach. Special Publication 800-160 Volume 1 Revision 1 describes a basis for engineering trustworthy secure systems~\parencite{Ross_Winstead_McEvilley_2022}. Special Publication 800-160 Volume 2 Revision 1 addresses cyber resiliency considerations~\parencite{NIST_SP_800_160_V2_2021}. These publications reference model-based approaches and traceability requirements without providing specific implementation guidance for Digital Engineering in enterprise IT contexts. The publications establish requirements that Digital Engineering could address---traceability between security requirements, design decisions, and implementation artifacts; documentation that maintains currency throughout system lifecycles; visibility into system configurations and relationships---yet they do not explicitly connect these requirements to Digital Engineering solutions.

Emerging research on compliance automation demonstrates that the academic community has recognized the inadequacy of manual compliance approaches, even if this recognition has not yet connected to the Digital Engineering discourse. \citeauthor{Santilli_2023} defined continuous compliance and identified thirteen requirements for automated, ongoing compliance verification from an industrial perspective~\parencite{Santilli_2023}. This definitional work establishes the intellectual foundations for a field that did not exist as a coherent research area a decade ago. \citeauthor{Angermeir_2024} extended this conceptual foundation through a design science methodology for continuous security compliance in highly regulated domains, demonstrating that automated compliance is not merely technically feasible but organizationally necessary as system complexity outpaces manual verification capacity~\parencite{Angermeir_2024}. \citeauthor{Castellanos_Ardila_2022} conducted a systematic literature review of compliance checking approaches for software processes, mapping the landscape of automated verification methods and identifying research directions~\parencite{Castellanos_Ardila_2022}.

\citeauthor{Joshi_Elluri_2020} developed a semantically rich knowledge graph capturing regulations from GDPR, PCI DSS, ISO 27001, NIST 800-53, and CSA CCM, enabling automated compliance checking for cloud services~\parencite{Joshi_Elluri_2020}. Their work, validated against privacy policies of major cloud providers, demonstrates that model-based approaches to compliance are technically feasible and practically valuable. \citeauthor{Banse_2021} presented the Cloud Property Graph, bridging static code analysis and runtime security assessment using an ontology of cloud resources to enable automated identification of misconfigurations and regulatory non-compliance across multi-vendor cloud deployments~\parencite{Banse_2021}. \citeauthor{Stojkov_2021} proposed a UML-based model for cross-standard security requirements with explicit mapping to NIST's Open Security Controls Assessment Language (OSCAL) Catalog Model, enabling organizations to track compliance across multiple frameworks simultaneously~\parencite{Stojkov_2021}. Most recently, \citeauthor{Koufos_2025} combined attack graphs with OSCAL using compliance-as-code principles to automate risk assessment~\parencite{Koufos_2025}.

The DevSecOps literature provides additional context for this compliance discussion. \citeauthor{Rajapakse_2022} conducted a systematic review of fifty-four peer-reviewed studies identifying twenty-one challenges and thirty-one solutions in DevSecOps adoption, classified into People, Practices, Tools, and Infrastructure themes~\parencite{Rajapakse_2022}. \citeauthor{Akbar_2022} identified eighteen challenges for DevSecOps mapped to ten core categories, finding that standards exert the most decisive influence on adoption outcomes~\parencite{Akbar_2022}. \citeauthor{Zhao_2024} performed a multi-vocal literature review identifying the primary dimensions of DevSecOps, providing a comprehensive mapping of the field's scope and boundaries~\parencite{Zhao_2024}. Earlier, \citeauthor{Myrbakken_2017} provided one of the first systematic examinations of DevSecOps, defining the field and characterizing the challenges of integrating security into DevOps practices~\parencite{Myrbakken_2017}. These DevSecOps studies establish the problem space---integrating security into development and operational pipelines---without connecting to the Digital Engineering framework that could provide structured methodology for that integration.

NIST's own OSCAL initiative represents institutional recognition that manual documentation approaches cannot sustain the accuracy and currency that compliance requires~\parencite{NIST_OSCAL_2023}. OSCAL provides standardized machine-readable formats for expressing security control catalogs, baselines, profiles, and assessment results. The initiative aligns with Digital Engineering's emphasis upon machine-readable documentation, and digital thread traceability could connect OSCAL compliance documentation to underlying system configurations, enabling automated verification that documented controls exist as implemented. Yet this integration has not been investigated in the academic literature. A notable finding from the literature search is that OSCAL has achieved strong government adoption but minimal peer-reviewed academic treatment---a gap that reflects the broader disconnect between compliance practice and academic research.

The compliance automation research and the Digital Engineering literature thus develop along parallel tracks that have not converged. Compliance researchers build knowledge graphs, property graphs, and domain-specific languages to automate regulatory assessment. Digital Engineering researchers develop model-based approaches, digital threads, and authoritative sources of truth for complex system management. Both communities address documentation accuracy, traceability, and automated verification. Neither community has systematically explored how integrating their approaches might produce capabilities exceeding what either achieves independently. This unexplored intersection represents a significant research opportunity that the present investigation begins to address by establishing whether the professionals who must implement compliance---IT and Information Assurance practitioners---recognize value in Digital Engineering capabilities.

\section{IT Service Management: Structural Failures Despite Mature Frameworks}

IT Service Management frameworks assume capabilities that current practices cannot sustain. ITIL provides comprehensive guidance for aligning IT services with business needs through structured processes, yet its effectiveness depends upon the accuracy and currency of underlying configuration information---accuracy that organizations consistently fail to achieve~\parencite{Cannon_AXELOS_2013}. Version 4 reorganized service management practices and introduced the Service Value System concept, acknowledging that tracking configurations across virtual systems, cloud computing, and cybersecurity domains presents challenges, but providing limited guidance on addressing the documentation accuracy challenges that undermine every ITIL process~\parencite{ITIL_4_2019}.

Empirical evidence for ITIL implementation challenges spans two decades of research yet reveals persistent rather than resolving problems. \citeauthor{Cook_2021} found resistance to change at twenty-seven percent as the top ITIL implementation challenge~\parencite{Cook_2021}. \citeauthor{Marrone_Kolbe_2011} surveyed 491 firms finding that while over ninety percent use ITSM frameworks, little research examines actual benefits realized~\parencite{Marrone_Kolbe_2011}. \citeauthor{Iden_2014} examined ITIL's role in IT governance through empirical investigation, finding that ITIL implementation success depends upon group efficacy and organizational resources, and that ITIL facilitates governance processes but ``lacks structural and relational governance practices''~\parencite{Iden_2014}. This finding carries particular significance for the present research: if ITIL provides process governance but lacks structural governance, and if Digital Engineering provides structural governance through model-based system representations, then integration of these approaches addresses a documented deficiency rather than introducing redundant capability.

\citeauthor{Joshi_2022} studied 881 companies worldwide and found that firms with superior IT governance processes achieve more than twenty-five percent higher profits than peer firms with poor governance~\parencite{Joshi_2022}. This finding quantifies the business impact of governance failures---the very failures that ITSM frameworks were designed to prevent but have not resolved. The parallel with MBSE evidence is striking: both MBSE and ITIL are widely adopted based upon perceived rather than measured value, and both face adoption challenges rooted in organizational factors rather than technical limitations. Yet no research examines whether integrating Digital Engineering practices with ITIL frameworks could address the persistent challenges that ITIL alone has not resolved.

Configuration Management Database failures provide the most extensively documented evidence of structural inadequacy. Gartner reports an eighty percent failure rate for CMDB implementations~\parencite{Gartner_CMDB_2019}. Additional research indicates that ninety-nine percent of organizations using CMDB tooling without addressing data quality gaps will experience visible business disruption~\parencite{Gartner_CMDB_2020}. Forrester research finds that less than half of organizations trust the data in their CMDB~\parencite{Forrester_CMDB_2020}. These industry findings are corroborated by peer-reviewed research: \citeauthor{Hauder_Matthes_Roth_2012} found through a study of 123 enterprise architecture practitioners that manual documentation processes cannot maintain accuracy in dynamic environments~\parencite{Hauder_Matthes_Roth_2012}. Data quality statistics reveal the core challenge: sixty percent of data manually input by employees proves inaccurate~\parencite{IBM_Data_Quality_2020}. A methodological observation warrants acknowledgment: the widely cited eighty percent CMDB failure rate originates from Gartner analyst reports rather than peer-reviewed empirical research. The absence of academic studies specifically documenting CMDB failure rates represents a gap between industry knowledge and academic evidence---a gap that itself reflects the practitioner-driven evolution of ITSM documented in the disciplinary history section of this chapter.

Recent analysis concludes that the CMDB approach itself has failed~\parencite{Forrester_CMDB_Dead_2025}. After decades of implementation attempts across organizations, CMDBs consistently fail to deliver intended value. The analysis attributes failures to structural issues: involving process experts rather than data management professionals, manual data entry that cannot maintain accuracy, and scope creep that renders CMDBs unmanageable. Forrester's research on Application and Infrastructure Dependency Mapping found that fifty-six percent of enterprises report incomplete views of dependencies between applications and underlying infrastructure~\parencite{Forrester_AIDM_2018}. This assessment suggests that incremental CMDB improvements cannot resolve inherent approach limitations---a conclusion that opens conceptual space for model-based alternatives that maintain accuracy through automated synchronization rather than manual data entry.

Shadow IT compounds the documentation challenge. Gartner research indicates forty-one percent of employees used shadow IT in 2022, expected to climb to seventy-five percent by 2027, with thirty to forty percent of large companies' IT expenditure representing shadow IT~\parencite{Gartner_Shadow_IT_2022}. \citeauthor{Haag_Eckhardt_2017} provided the foundational definition of shadow IT, estimating that the true extent of shadow IT is ``ten times greater than what CIOs suspect'' and identifying key risk factors including security vulnerabilities, compliance violations, and loss of IT control~\parencite{Haag_Eckhardt_2017}. \citeauthor{Klotz_2019} conducted a systematic review of 126 publications documenting how silos between business units and IT departments drive shadow IT, creating security risks, data inconsistency, and compliance violations~\parencite{Klotz_2019}. Systems deployed outside formal governance remain invisible to IT operations and security teams, creating unknown attack surfaces that no documentation process can capture. \citeauthor{Furstenau_2021} examined organizational dynamics when hidden IT systems are discovered, revealing interdepartmental conflicts and governance failures that perpetuate documentation gaps~\parencite{Furstenau_2021}. The shadow IT phenomenon reflects a structural mismatch between IT governance and organizational needs: when official IT processes cannot meet user requirements quickly enough, users acquire solutions independently, creating operational dependencies that official documentation does not capture.

Change management effectiveness depends directly upon documentation accuracy. Industry analysis confirms that reliance upon outdated documentation leads to inaccurate impact assessments~\parencite{Freshservice_Change_2021}. Research by \citeauthor{Bokan_Santos_2021} highlights difficulties organizations encounter in maintaining comprehensive security oversight~\parencite{Bokan_Santos_2021}. Change management depends upon accurate understanding of system relationships~\parencite{iso20000_2018} that current documentation approaches cannot maintain. Every change approved based upon inaccurate documentation represents a potential incident. When impact assessments miss dependencies that exist in operational systems, changes cause unintended effects that consume resources, damage trust in change processes, and create pressure for emergency changes that further degrade documentation accuracy. The resulting cycle is self-reinforcing and resistant to process improvement within the document-centric paradigm.

\citeauthor{thompson2019integrating} examined integrating MBSE with IT Service Management, and previous research by \citeauthor{Bonar_Hastings_2024} demonstrated that compliance verification is enhanced by Digital Engineering practices~\parencite{thompson2019integrating, Bonar_Hastings_2024}. These preliminary investigations suggest that integration between Digital Engineering and IT Service Management offers value, though comprehensive research remains absent.

\section{Enterprise Visibility: Empirical Evidence of Systemic Failure}\label{sec:enterprise_visibility}

The challenges documented in the preceding sections share common roots in the inability of organizations to maintain accurate, current documentation of their enterprise information systems. This section synthesizes peer-reviewed research and industry analysis to establish that these challenges reflect systemic patterns rather than isolated organizational deficiencies, and to provide the empirical foundation for evaluating Digital Engineering as a potential disciplinary response.

Research consistently documents that organizations lack visibility into large portions of their IT environments. \citeauthor{IDC_Exabeam_2023} found that organizations globally can monitor only sixty-six percent of their IT environments, leaving blind spots particularly in cloud deployments~\parencite{IDC_Exabeam_2023}. The Ponemon Institute's Global Study on Closing the IT Security Gap found that sixty-three percent of security teams lack visibility and control into all user device activity connected to their infrastructure~\parencite{Ponemon_Visibility_2023}. The SANS Institute SOC Survey found that only fifteen percent of respondents expressed very high confidence that all devices on their network are discoverable~\parencite{SANS_SOC_Survey_2023}. These visibility gaps compound across organizational boundaries. Ivanti's State of Cybersecurity Trends Report found that fifty-five percent of organizations maintain security and IT data silos, with sixty-two percent reporting that silos slow security response times~\parencite{Ivanti_Cybersecurity_2025}. The Cloud Security Alliance revealed that ninety-five percent of organizations suffered cloud-related breaches in the preceding eighteen months~\parencite{CSA_Cloud_Security_2024}. Check Point found that eighty-two percent of enterprises experienced security incidents due to cloud misconfigurations, while sixty-seven percent struggle with limited visibility into cloud infrastructure~\parencite{Check_Point_Cloud_2024}.

Peer-reviewed research provides empirical grounding for these industry findings. \citeauthor{Yin_Yuan_Lu_2011} conducted an empirical study examining configuration errors in commercial and open source systems, finding that seventy to eighty-five percent of misconfigurations result from mistakes in setting configuration parameters and that twenty-two to fifty-seven percent of misconfigurations involve configurations external to the examined system~\parencite{Yin_Yuan_Lu_2011}. NIST Special Publication 800-128 defines configuration drift as systems deviating from baseline configurations over time through manual interventions, software updates, and environmental factors~\parencite{NIST_SP_800_128}. The Uptime Institute's Annual Outage Analysis confirms that sixty-four percent of IT system outages occurred because of configuration or change management issues~\parencite{Uptime_Outage_2023}. The IT Process Institute established that eighty percent of unplanned outages result from ill-planned changes made by administrators or developers~\parencite{IT_Process_Institute_2004}---changes that proper dependency documentation would have flagged.

Breach detection times serve as proxy measures for organizational visibility. \citeauthor{IBM_Ponemon_2024} report that the mean time to identify breaches reached two hundred four days, with breaches involving lifecycles exceeding two hundred days costing an average of 5.46 million dollars~\parencite{IBM_Ponemon_2024}. The 2025 report found that thirty-five percent of breaches involved shadow data---information stored in unmanaged locations---and forty percent involved data stored across multiple environments that organizations struggle to inventory comprehensively~\parencite{IBM_Ponemon_2025}. These findings demonstrate that visibility failures directly impact security outcomes in measurable economic terms.

Peer-reviewed research provides theoretical and empirical frameworks for understanding why these failures persist. \citeauthor{Bento_Tagliabue_Lorenzo_2020} conducted a scoping review of forty studies on organizational silos, identifying five conceptualizations and characterizing silo mentality as an absence of systems thinking and organizational vision~\parencite{Bento_Tagliabue_Lorenzo_2020}. \citeauthor{Beese_2023} demonstrated through PLS-SEM analysis of 249 information systems managers that IS architecture complexity significantly reduces efficiency, flexibility, transparency, and predictability, and that organizations without adequate enterprise architecture management face compounding architectural degradation~\parencite{Beese_2023}. \citeauthor{Tamm_2022} investigated how enterprise architecture leads to organizational benefits through twenty-two expert interviews and two case studies, finding that ``many EA initiatives in practice fail or do not live up to stakeholder expectations'' and that benefit realization mechanisms remain ``not fully understood''~\parencite{Tamm_2022}. \citeauthor{Pattij_2022} applied fuzzy-set qualitative comparative analysis to investigate how enterprise architecture management contributes to digital transformation capabilities, identifying configurational paths to effectiveness that require combinations of factors rather than any single intervention~\parencite{Pattij_2022}. \citeauthor{van_de_Wetering_2022} surveyed 414 senior practitioners and found that many enterprise architecture initiatives ``fail or do not live up to stakeholder expectations,'' reinforcing the pattern of enterprise architecture as a discipline with acknowledged value but unreliable execution~\parencite{van_de_Wetering_2022}. \citeauthor{Kotusev_2019} examined twenty-seven organizations and found that prescribed enterprise architecture artifact lists from frameworks like TOGAF were never empirically validated and do not reflect actual practice---documenting a fundamental gap between what frameworks recommend and what organizations find useful~\parencite{Kotusev_2019}. \citeauthor{Kurnia_2021} identified inhibitors to stakeholder engagement in enterprise architecture practice, including organizational silos, political barriers, and poor cross-team communication that directly undermine documentation quality and IT governance effectiveness~\parencite{Kurnia_2021}. \citeauthor{Bree_Karger_2022} conducted a systematic literature review organizing enterprise architecture management challenges into six dimensions, with documentation challenges including dearth of automated tools, immature documentation models, and insufficient emphasis on forward-looking documentation~\parencite{Bree_Karger_2022}.

Complexity theory provides an explanatory framework for why traditional documentation approaches fail in modern enterprise environments. \citeauthor{Benbya_McKelvey_2006} applied Complex Adaptive Systems theory to information systems development, proposing seven first principles of adaptive success and arguing that if complexity is not managed appropriately, information systems fail~\parencite{Benbya_McKelvey_2006}. \citeauthor{Benbya_Nan_Tanriverdi_Yoo_2020} demonstrated that enterprise information systems have reached complexity levels exceeding prior technological generations~\parencite{Benbya_Nan_Tanriverdi_Yoo_2020}. Enterprise IT environments exhibit characteristics of complex adaptive systems---numerous interconnected components, emergent behaviors arising from component interactions, continuous change, and unpredictable responses to interventions---that static documentation approaches assume remain stable between documentation updates.

Technical debt research adds further perspective. \citeauthor{Santos_2019} specifically addressed documentation technical debt---problems concerning non-existent, inadequate, or incomplete software project documentation~\parencite{Santos_2019}. \citeauthor{Li_Avgeriou_Liang_2015} conducted a systematic mapping study covering ninety-four studies establishing technical debt taxonomy and management frameworks, including documentation debt as a distinct category~\parencite{Li_Avgeriou_Liang_2015}. \citeauthor{Junior_Travassos_2022} consolidated perspectives on technical debt across nineteen secondary studies~\parencite{Junior_Travassos_2022}. \citeauthor{Kleinwaks_2023} extended technical debt concepts to systems engineering contexts~\parencite{Kleinwaks_2023}. Documentation technical debt accumulates when organizations defer documentation updates to prioritize operational activities. Unlike code technical debt, documentation debt remains invisible until documentation is needed for change impact assessment, incident response, or compliance verification---at which point the accumulated debt imposes costs far exceeding the original deferral savings.

Table~\ref{tab:visibilityStatistics} summarizes the evidence documenting enterprise visibility and documentation failures across peer-reviewed and industry research sources.

\begin{table}[H]
  \centering
  \caption{Enterprise Visibility and Documentation Failure Evidence}\label{tab:visibilityStatistics}
  \small
  \begin{tabular}{@{}p{3.0in}p{1.0in}p{2.0in}@{}}
    \toprule
    \textbf{Finding} & \textbf{Statistic} & \textbf{Source} \\
    \midrule
    \multicolumn{3}{@{}c@{}}{\textit{Visibility Gap Metrics}} \\
    \midrule
    IT environment monitorable & 66\% & \parencite{IDC_Exabeam_2023} \\
    \midrule
    Security teams lacking device visibility & 63\% & \parencite{Ponemon_Visibility_2023} \\
    \midrule
    High confidence in device discovery & 15\% & \parencite{SANS_SOC_Survey_2023} \\
    \midrule
    Organizations with security/IT silos & 55\% & \parencite{Ivanti_Cybersecurity_2025} \\
    \midrule
    \multicolumn{3}{@{}c@{}}{\textit{Configuration Management Failures}} \\
    \midrule
    CMDB implementation failure rate & 80\% & \parencite{Gartner_CMDB_2019,Gartner_CMDB_2020} \\
    \midrule
    Outages from configuration issues & 64\% & \parencite{Uptime_Outage_2023} \\
    \midrule
    Misconfigurations from parameter errors & 70-85\% & \parencite{Yin_Yuan_Lu_2011} \\
    \midrule
    Unplanned outages from ill-planned changes & 80\% & \parencite{IT_Process_Institute_2004} \\
    \midrule
    \multicolumn{3}{@{}c@{}}{\textit{Shadow IT and Undocumented Assets}} \\
    \midrule
    Shadow IT as percentage of IT spend & 30-40\% & \parencite{Gartner_Shadow_IT_2022} \\
    \midrule
    Cisco cloud services vs. IT estimates & 15-22x higher & \parencite{Cisco_Cloud_Services_2016} \\
    \midrule
    Employees using shadow IT (2022) & 41\% & \parencite{Gartner_Shadow_IT_2022} \\
    \midrule
    Projected shadow IT usage (2027) & 75\% & \parencite{Gartner_Shadow_IT_2022} \\
    \midrule
    \multicolumn{3}{@{}c@{}}{\textit{Security Impact Metrics}} \\
    \midrule
    Mean time to identify breach & 204 days & \parencite{IBM_Ponemon_2024} \\
    \midrule
    Cloud breaches from misconfigurations & 82\% & \parencite{Check_Point_Cloud_2024} \\
    \midrule
    Organizations with cloud breaches (18 mo) & 95\% & \parencite{CSA_Cloud_Security_2024} \\
    \midrule
    Projected preventable cloud breaches (2027) & 99\% & \parencite{Gartner_Cloud_Misconfiguration_2024} \\
    \bottomrule
  \end{tabular}
\end{table}

The convergence of peer-reviewed empirical research and industry analysis establishes that enterprise visibility and documentation failures represent a systemic challenge rather than isolated organizational deficiencies. Traditional documentation approaches---manual configuration tracking, periodic documentation updates, static architecture diagrams---cannot maintain accuracy in environments characterized by continuous change, complex dependencies, and organizational silos.

A methodological observation regarding the evidentiary sources presented in this section warrants acknowledgment. The enterprise visibility evidence draws substantially upon industry analyst reports and practitioner surveys alongside peer-reviewed academic research. This reliance upon industry gray literature reflects a characteristic of the research domain rather than an analytical preference: the operational challenges of enterprise IT documentation and visibility have received considerably more attention from industry analysts and practitioner communities than from academic researchers. The relative scarcity of peer-reviewed empirical studies quantifying CMDB failure rates, shadow IT prevalence, and breach detection timelines itself constitutes evidence of the research gap this dissertation addresses. Where peer-reviewed evidence corroborates industry findings---as with the work of \citeauthor{Hauder_Matthes_Roth_2012} on documentation accuracy, \citeauthor{Santos_2019} on documentation technical debt, \citeauthor{Beese_2023} on architecture complexity, \citeauthor{Tamm_2022} on enterprise architecture failures, and \citeauthor{Kotusev_2019} on enterprise architecture practice---the convergence strengthens confidence in the broader pattern. The industry evidence is presented not as a substitute for academic rigor but as the best available evidence for phenomena that academic research has not yet systematically investigated.

\section{Research Gaps and Theoretical Framework}

The systematic literature review reveals a pattern: frameworks and compliance requirements assume documentation and visibility capabilities that organizations demonstrably lack, while Digital Engineering methodologies that could address these capabilities remain confined within a discipline that enterprise IT and Information Assurance have not engaged. This section synthesizes the findings into a theoretical framework while documenting the research gaps that this investigation begins to address.

The academic research gap is pronounced. Systematic literature reviews examining MBSE consistently find no research addressing enterprise IT infrastructure or Information Assurance applications beyond the preliminary reference model by \citeauthor{Bonar_Hastings_2024}~\parencite{Bonar_Hastings_2024} and the conceptual DevSecOps framework by \citeauthor{CMU_SEI_DevSecOps_2023}~\parencite{CMU_SEI_DevSecOps_2023}. This gap persists despite explicit requirements in compliance frameworks for capabilities that Digital Engineering provides. As the disciplinary history presented in this chapter demonstrates, the gap cannot be attributed to Digital Engineering immaturity---defense and aerospace have employed Digital Engineering successfully for years. Nor can it be attributed to tool unavailability---MBSE tools, digital twin platforms, and PLM systems have existed for over a decade (MBSE) to decades (digital twin, PLM, \& authoritative traceability). Rather, the gap reflects disciplinary boundaries that formed when systems engineering, information assurance, cybersecurity, and IT service management each developed independent academic identities, professional communities, and research traditions. What \citeauthor{Henderson_Salado_2024_Org} would characterize as low interconnectedness between organizational units---precisely the structural condition their research associates with impeded adoption---operates at the disciplinary level itself~\parencite{Henderson_Salado_2024_Org}.

Standards bodies have recognized enterprise applicability of systems engineering approaches. The Unified Architecture Framework provides viewpoints applicable to enterprise IT\@. NIST publications require enterprise architecture capabilities for compliance. ITIL requires visibility and documentation that model-based approaches could provide. Yet academic research has not examined practical application. This standards-research disconnect leaves practitioners without empirical guidance for applying available standards to enterprise IT challenges.

Table~\ref{tab:researchGaps} summarizes the research gaps identified across the literature domains examined in this review.

\begin{table}[htbp]
  \centering
  \caption{Research Gaps Within Corpus of Knowledge}\label{tab:researchGaps}
  \small
  \begin{tabular}{@{}p{1.8in}p{2.1in}p{2.2in}@{}}
    \toprule
    \textbf{Domain} & \textbf{Gap Description} & \textbf{Research Implication} \\
    \midrule
    MBSE for Enterprise IT & One study applying MBSE to enterprise IT, none for IA program management & Foundation research required \\
    \midrule
    MBSE Adoption Evidence & Adoption studies limited to SE populations; no data from IT or IA professionals & Perception measurement needed in new populations \\
    \midrule
    Disciplinary Integration & No research connecting SE, IA, cybersecurity, and ITSM methodologies despite shared challenges & Cross-disciplinary investigation needed \\
    \midrule
    Digital Threads & No research on traceability for IT/IA contexts & Conceptual validation needed \\
    \midrule
    Digital Twin & Growing security application research but no enterprise IT integration studies & Application studies needed \\
    \midrule
    ITSM Integration & No frameworks integrating DE with ITIL & Integration research required \\
    \midrule
    Compliance Automation & Model-based compliance research and DE research develop on parallel tracks without convergence & Integration research needed \\
    \midrule
    Adoption Theory & Cybersecurity adoption and MBSE adoption research use same theories but never intersect & Bridging research needed \\
    \midrule
    Open Source & No academic validation for enterprise IT & Evaluation research needed \\
    \midrule
    Professional Perceptions & Unknown awareness and perceived value among IT/IA professionals & This research addresses \\
    \bottomrule
  \end{tabular}
\end{table}

Based upon the systematic literature review, this research adopts a theoretical framework integrating Digital Engineering principles with established Information Assurance and IT Service Management practices. This framework posits that Digital Engineering represents a disciplinary approach with demonstrated value in defense and aerospace contexts whose capabilities align with gaps that have persisted in enterprise IT despite decades of framework development and organizational investment. The framework does not assert that Digital Engineering will resolve these gaps in enterprise IT contexts---that remains an empirical question. Rather, it identifies structural correspondences between demonstrated Digital Engineering capabilities and documented enterprise IT challenges, establishing the theoretical basis for investigating whether practitioners recognize these correspondences.

The persistent failures documented in IT Service Management and Information Assurance practices share common root causes that Digital Engineering practices are designed to address. Organizations struggle with documentation accuracy because traditional approaches rely upon manual processes disconnected from operational systems. Organizations fail to maintain traceability because document-centric methods cannot sustain verified connections as systems evolve. Organizations lack visibility because static artifacts cannot represent dynamic system states. Digital Engineering's demonstrated ability to address these root causes in defense and aerospace contexts motivates investigation of whether similar benefits may transfer to enterprise IT environments.

The DoD Digital Engineering Strategy defines the authoritative source of truth as ``a single source of data and models'' that provides ``a definitive technical baseline'' for programs~\parencite{DoD_DE_Strategy_2018}. Current IT and Information Assurance practices lack authoritative sources of truth, instead maintaining multiple disconnected documentation artifacts that diverge over time. Digital threads establish and maintain authoritative traceability throughout system lifecycles, addressing the gap between security requirements, control implementations, and compliance evidence. Digital twin capabilities enable organizations to simulate system behavior, test proposed changes, and analyze scenarios without affecting production systems. Model-based approaches maintain synchronization with operational systems, providing the visibility that manual documentation cannot sustain.

The theoretical framework acknowledges several limitations. First, it extrapolates from Digital Engineering value demonstrated in aerospace and defense to anticipated value in enterprise IT contexts. Whether benefits demonstrated for physical systems transfer to logical information systems remains unvalidated. Second, it assumes that Digital Engineering tools and methodologies can be adapted for enterprise IT contexts. \citeauthor{Mazeika_Butleris_2020} documented that current MBSE methods inadequately address security requirements~\parencite{Mazeika_Butleris_2020}, suggesting adaptation requirements may exceed anticipated effort. Third, the framework does not address organizational change management, workforce development, or cultural transformation requirements. The adoption barriers documented by \citeauthor{Henderson_McDermott_Salado_2024}---including middle management resistance, awareness deficits, and the need for dedicated MBSE teams~\parencite{Henderson_McDermott_Salado_2024}---would likely manifest with greater intensity in domains unfamiliar with systems engineering practices. Fourth, the framework focuses upon potential benefits without comprehensive analysis of costs or implementation challenges. Cost-benefit analysis requires empirical data this research does not collect.

\section{Chapter Summary}

This literature review has examined the current body of knowledge across interconnected domains relevant to applying Digital Engineering methodologies to Information Assurance and IT Service Management, advancing four interrelated arguments that position the present research within the academic conversation.

First, the independent evolution of systems engineering, information assurance, cybersecurity, and IT service management as separate academic and professional disciplines created structural barriers to cross-disciplinary methodological exchange. Systems engineering emerged from defense laboratories and engineering departments; information assurance grew from national security policy and computing education; cybersecurity crystallized as a meta-discipline drawing from multiple computing fields; and IT service management developed as a practitioner-driven domain with limited academic theorization. These parallel trajectories produced separate journals, conferences, curricular standards, and professional communities---institutional structures that explain the absence of research connecting Digital Engineering to enterprise IT and Information Assurance.

Second, the evidence base for MBSE value, while compelling in individual cases such as the eighteen percent efficiency improvement and nine percent defect reduction documented by \citeauthor{Rogers_Mitchell_2021}~\parencite{Rogers_Mitchell_2021}, remains disproportionately reliant upon perceived rather than measured outcomes. \citeauthor{Henderson_Salado_2021} found that approximately two-thirds of claimed benefits lack empirical measurement~\parencite{Henderson_Salado_2021}. Efforts to develop measurement frameworks by \citeauthor{Henderson_2023_Metrics} and evaluations of perceived value by \citeauthor{Campo_2023} have advanced the methodological conversation without resolving the measurement deficit~\parencite{Henderson_2023_Metrics, Campo_2023}. This evidence deficit creates rational hesitation among organizations outside the systems engineering discipline, where institutional experience cannot compensate for the measurement gap.

Third, adoption research demonstrates that perceptions govern adoption decisions more powerfully than objective technical merit. \citeauthor{Call_2024} showed that perceived complexity and compatibility barriers impede adoption even among systems engineering professionals who recognize MBSE's relative advantage~\parencite{Call_2024}. \citeauthor{Henderson_McDermott_Salado_2024} found that twenty-two percent of systems engineering professionals cannot clearly define MBSE~\parencite{Henderson_McDermott_Salado_2024}. Parallel research in cybersecurity contexts by \citeauthor{Hasani_2023} and \citeauthor{Anthony_2024} demonstrates that the same adoption theories and barrier patterns operate across technology domains~\parencite{Hasani_2023, Anthony_2024}. If awareness deficits and perception barriers persist within the originating discipline, their magnitude among IT and Information Assurance professionals---who operate outside the systems engineering discipline entirely---demands empirical measurement rather than assumption.

Fourth, compliance frameworks and IT service management standards require capabilities that current practices demonstrably fail to provide, while Digital Engineering offers those capabilities in adjacent domains. The enterprise visibility evidence---sixty-six percent IT environment monitoring, eighty percent CMDB failure rates, 204-day average breach detection times---documents the scope of failure. Enterprise architecture research by \citeauthor{Tamm_2022} and \citeauthor{van_de_Wetering_2022} confirms that EA initiatives frequently fail to meet stakeholder expectations~\parencite{Tamm_2022, van_de_Wetering_2022}. The compliance automation literature, including emerging work on continuous compliance by \citeauthor{Santilli_2023} and \citeauthor{Angermeir_2024}, demonstrates growing recognition that model-based approaches can address documentation and traceability requirements~\parencite{Santilli_2023, Angermeir_2024}. Yet no research connects these parallel tracks by examining Digital Engineering as an integrated solution for enterprise IT and Information Assurance challenges.

The theoretical framework developed from this synthesis posits that structural correspondences between demonstrated Digital Engineering capabilities and documented enterprise IT challenges warrant investigation of whether practitioners recognize these correspondences. The research contributes by investigating whether IT and Information Assurance professionals perceive value in Digital Engineering capabilities. If professionals perceive value, findings justify subsequent implementation research. If professionals do not perceive value despite documented challenges, findings challenge the theoretical premise and identify barriers requiring address before adoption can occur.

Chapter 3 presents the research methodology employed to investigate professional awareness and perceptions of Digital Engineering capabilities. The methodology utilizes a quantitative survey-based approach following a systems engineering lifecycle to ensure rigor and traceability throughout the research process.